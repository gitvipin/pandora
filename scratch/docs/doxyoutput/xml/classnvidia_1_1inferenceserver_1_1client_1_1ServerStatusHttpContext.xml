<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.11">
  <compounddef id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext" kind="class" language="C++" prot="public">
    <compoundname>nvidia::inferenceserver::client::ServerStatusHttpContext</compoundname>
    <basecompoundref refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext" prot="public" virt="non-virtual">nvidia::inferenceserver::client::ServerStatusContext</basecompoundref>
    <includes refid="request_8h" local="no">request.h</includes>
      <sectiondef kind="private-attrib">
      <memberdef kind="variable" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1abfe3a356d18bba71bbfb3c6a51669acd" prot="private" static="no" mutable="no">
        <type>const std::string</type>
        <definition>const std::string nvidia::inferenceserver::client::ServerStatusHttpContext::url_</definition>
        <argsstring></argsstring>
        <name>url_</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="878" column="1" bodyfile="src/clients/c++/request.h" bodystart="878" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a62fdc6f56d34f7f38d82ceca58434889" prot="private" static="no" mutable="no">
        <type>RequestStatus</type>
        <definition>RequestStatus nvidia::inferenceserver::client::ServerStatusHttpContext::request_status_</definition>
        <argsstring></argsstring>
        <name>request_status_</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="881" column="1" bodyfile="src/clients/c++/request.h" bodystart="881" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a3082656fbb2bb6dcab49f60552963658" prot="private" static="no" mutable="no">
        <type>std::string</type>
        <definition>std::string nvidia::inferenceserver::client::ServerStatusHttpContext::response_</definition>
        <argsstring></argsstring>
        <name>response_</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="884" column="1" bodyfile="src/clients/c++/request.h" bodystart="884" bodyend="-1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="public-static-func">
      <memberdef kind="function" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1ab4b5945eb886c8a4e643f249d1bee2b0" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type><ref refid="classnvidia_1_1inferenceserver_1_1client_1_1Error" kindref="compound">Error</ref></type>
        <definition>static Error nvidia::inferenceserver::client::ServerStatusHttpContext::Create</definition>
        <argsstring>(std::unique_ptr&lt; ServerStatusContext &gt; *ctx, const std::string &amp;server_url, bool verbose=false)</argsstring>
        <name>Create</name>
        <param>
          <type>std::unique_ptr&lt; <ref refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext" kindref="compound">ServerStatusContext</ref> &gt; *</type>
          <declname>ctx</declname>
        </param>
        <param>
          <type>const std::string &amp;</type>
          <declname>server_url</declname>
        </param>
        <param>
          <type>bool</type>
          <declname>verbose</declname>
          <defval>false</defval>
        </param>
        <briefdescription>
<para>Create a context that returns information about an inference server and all models on the server using HTTP protocol. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>ctx</parametername>
</parameternamelist>
<parameterdescription>
<para>Returns a new <ref refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext" kindref="compound">ServerStatusHttpContext</ref> object. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>server_url</parametername>
</parameternamelist>
<parameterdescription>
<para>The inference server name and port. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>verbose</parametername>
</parameternamelist>
<parameterdescription>
<para>If true generate verbose output when contacting the inference server. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para><ref refid="classnvidia_1_1inferenceserver_1_1client_1_1Error" kindref="compound">Error</ref> object indicating success or failure. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="849" column="1"/>
      </memberdef>
      <memberdef kind="function" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1ac0cb2c45a1d73ab6f45c1397f14ba6f9" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type><ref refid="classnvidia_1_1inferenceserver_1_1client_1_1Error" kindref="compound">Error</ref></type>
        <definition>static Error nvidia::inferenceserver::client::ServerStatusHttpContext::Create</definition>
        <argsstring>(std::unique_ptr&lt; ServerStatusContext &gt; *ctx, const std::string &amp;server_url, const std::string &amp;model_name, bool verbose=false)</argsstring>
        <name>Create</name>
        <param>
          <type>std::unique_ptr&lt; <ref refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext" kindref="compound">ServerStatusContext</ref> &gt; *</type>
          <declname>ctx</declname>
        </param>
        <param>
          <type>const std::string &amp;</type>
          <declname>server_url</declname>
        </param>
        <param>
          <type>const std::string &amp;</type>
          <declname>model_name</declname>
        </param>
        <param>
          <type>bool</type>
          <declname>verbose</declname>
          <defval>false</defval>
        </param>
        <briefdescription>
<para>Create a context that returns information about an inference server and one model on the sever using HTTP protocol. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>ctx</parametername>
</parameternamelist>
<parameterdescription>
<para>Returns a new <ref refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext" kindref="compound">ServerStatusHttpContext</ref> object. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>server_url</parametername>
</parameternamelist>
<parameterdescription>
<para>The inference server name and port. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>model_name</parametername>
</parameternamelist>
<parameterdescription>
<para>The name of the model to get status for. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>verbose</parametername>
</parameternamelist>
<parameterdescription>
<para>If true generate verbose output when contacting the inference server. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para><ref refid="classnvidia_1_1inferenceserver_1_1client_1_1Error" kindref="compound">Error</ref> object indicating success or failure. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="861" column="1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="public-func">
      <memberdef kind="function" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a587d9241ae9b011307592b4ce0a312d3" prot="public" static="no" const="no" explicit="no" inline="no" virt="virtual">
        <type><ref refid="classnvidia_1_1inferenceserver_1_1client_1_1Error" kindref="compound">Error</ref></type>
        <definition>Error nvidia::inferenceserver::client::ServerStatusHttpContext::GetServerStatus</definition>
        <argsstring>(ServerStatus *status) override</argsstring>
        <name>GetServerStatus</name>
        <reimplements refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext_1a15b5f463eb3c8315b56f21b67b151d04">GetServerStatus</reimplements>
        <param>
          <type>ServerStatus *</type>
          <declname>status</declname>
        </param>
        <briefdescription>
<para>Contact the inference server and get status. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>status</parametername>
</parameternamelist>
<parameterdescription>
<para>Returns the status. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para><ref refid="classnvidia_1_1inferenceserver_1_1client_1_1Error" kindref="compound">Error</ref> object indicating success or failure. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="868" column="1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="private-static-func">
      <memberdef kind="function" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1aff997f89b5e55f4d654b18bbc629440e" prot="private" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>size_t</type>
        <definition>static size_t nvidia::inferenceserver::client::ServerStatusHttpContext::ResponseHeaderHandler</definition>
        <argsstring>(void *, size_t, size_t, void *)</argsstring>
        <name>ResponseHeaderHandler</name>
        <param>
          <type>void *</type>
        </param>
        <param>
          <type>size_t</type>
        </param>
        <param>
          <type>size_t</type>
        </param>
        <param>
          <type>void *</type>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="871" column="1"/>
      </memberdef>
      <memberdef kind="function" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a4fc9f5e9ba49c5e7c77a3f767c02eb67" prot="private" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>size_t</type>
        <definition>static size_t nvidia::inferenceserver::client::ServerStatusHttpContext::ResponseHandler</definition>
        <argsstring>(void *, size_t, size_t, void *)</argsstring>
        <name>ResponseHandler</name>
        <param>
          <type>void *</type>
        </param>
        <param>
          <type>size_t</type>
        </param>
        <param>
          <type>size_t</type>
        </param>
        <param>
          <type>void *</type>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="872" column="1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="private-func">
      <memberdef kind="function" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a0f425167e8ae244b39d2246ab718c6a4" prot="private" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type></type>
        <definition>nvidia::inferenceserver::client::ServerStatusHttpContext::ServerStatusHttpContext</definition>
        <argsstring>(const std::string &amp;, bool)</argsstring>
        <name>ServerStatusHttpContext</name>
        <param>
          <type>const std::string &amp;</type>
        </param>
        <param>
          <type>bool</type>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="874" column="1"/>
      </memberdef>
      <memberdef kind="function" id="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a39c3af77607c56c90f922788f1707333" prot="private" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type></type>
        <definition>nvidia::inferenceserver::client::ServerStatusHttpContext::ServerStatusHttpContext</definition>
        <argsstring>(const std::string &amp;, const std::string &amp;, bool)</argsstring>
        <name>ServerStatusHttpContext</name>
        <param>
          <type>const std::string &amp;</type>
        </param>
        <param>
          <type>const std::string &amp;</type>
        </param>
        <param>
          <type>bool</type>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="875" column="1"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
<para><ref refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext" kindref="compound">ServerStatusHttpContext</ref> is the HTTP instantiation of <ref refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext" kindref="compound">ServerStatusContext</ref>. </para>    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <inheritancegraph>
      <node id="155">
        <label>nvidia::inferenceserver::client::ServerStatusContext</label>
        <link refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext"/>
      </node>
      <node id="154">
        <label>nvidia::inferenceserver::client::ServerStatusHttpContext</label>
        <link refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext"/>
        <childnode refid="155" relation="public-inheritance">
        </childnode>
      </node>
    </inheritancegraph>
    <collaborationgraph>
      <node id="157">
        <label>nvidia::inferenceserver::client::ServerStatusContext</label>
        <link refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext"/>
      </node>
      <node id="156">
        <label>nvidia::inferenceserver::client::ServerStatusHttpContext</label>
        <link refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext"/>
        <childnode refid="157" relation="public-inheritance">
        </childnode>
      </node>
    </collaborationgraph>
    <location file="src/clients/c++/request.h" line="840" column="1" bodyfile="src/clients/c++/request.h" bodystart="840" bodyend="885"/>
    <listofallmembers>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1ab4b5945eb886c8a4e643f249d1bee2b0" prot="public" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>Create</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1ac0cb2c45a1d73ab6f45c1397f14ba6f9" prot="public" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>Create</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a587d9241ae9b011307592b4ce0a312d3" prot="public" virt="virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>GetServerStatus</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a62fdc6f56d34f7f38d82ceca58434889" prot="private" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>request_status_</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a3082656fbb2bb6dcab49f60552963658" prot="private" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>response_</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a4fc9f5e9ba49c5e7c77a3f767c02eb67" prot="private" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>ResponseHandler</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1aff997f89b5e55f4d654b18bbc629440e" prot="private" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>ResponseHeaderHandler</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext_1af8209b3b4715d25a66431c1e3b9fe27e" prot="protected" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>ServerStatusContext</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a0f425167e8ae244b39d2246ab718c6a4" prot="private" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>ServerStatusHttpContext</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1a39c3af77607c56c90f922788f1707333" prot="private" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>ServerStatusHttpContext</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusHttpContext_1abfe3a356d18bba71bbfb3c6a51669acd" prot="private" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>url_</name></member>
      <member refid="classnvidia_1_1inferenceserver_1_1client_1_1ServerStatusContext_1aade2733abe3cf60dfa59bc9352c0fbf2" prot="protected" virt="non-virtual"><scope>nvidia::inferenceserver::client::ServerStatusHttpContext</scope><name>verbose_</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>
