<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.11">
  <compounddef id="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat" kind="struct" language="C++" prot="public">
    <compoundname>nvidia::inferenceserver::client::InferContext::Stat</compoundname>
    <includes refid="request_8h" local="no">request.h</includes>
      <sectiondef kind="public-attrib">
      <memberdef kind="variable" id="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1ad76e90f2ef845eb146acab963bbffd1a" prot="public" static="no" mutable="no">
        <type>size_t</type>
        <definition>size_t nvidia::inferenceserver::client::InferContext::Stat::completed_request_count</definition>
        <argsstring></argsstring>
        <name>completed_request_count</name>
        <briefdescription>
<para>Total number of requests completed. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="530" column="1" bodyfile="src/clients/c++/request.h" bodystart="530" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1abf5e228bd9de072b92cdbfd06b10c8cf" prot="public" static="no" mutable="no">
        <type>uint64_t</type>
        <definition>uint64_t nvidia::inferenceserver::client::InferContext::Stat::cumulative_total_request_time_ns</definition>
        <argsstring></argsstring>
        <name>cumulative_total_request_time_ns</name>
        <briefdescription>
<para>Time from the request start until the response is completely received. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="534" column="1" bodyfile="src/clients/c++/request.h" bodystart="534" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1a5b8451d591204705cfb9d8854f132b18" prot="public" static="no" mutable="no">
        <type>uint64_t</type>
        <definition>uint64_t nvidia::inferenceserver::client::InferContext::Stat::cumulative_send_time_ns</definition>
        <argsstring></argsstring>
        <name>cumulative_send_time_ns</name>
        <briefdescription>
<para>Time from the request start until the last byte is sent. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="537" column="1" bodyfile="src/clients/c++/request.h" bodystart="537" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1ae113efbf699abdd52d45996dcc7d4689" prot="public" static="no" mutable="no">
        <type>uint64_t</type>
        <definition>uint64_t nvidia::inferenceserver::client::InferContext::Stat::cumulative_receive_time_ns</definition>
        <argsstring></argsstring>
        <name>cumulative_receive_time_ns</name>
        <briefdescription>
<para>Time from receiving first byte of the response until the response is completely received. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="541" column="1" bodyfile="src/clients/c++/request.h" bodystart="541" bodyend="-1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="public-func">
      <memberdef kind="function" id="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1aa1c18a68160ee9ccb7002fdb40e7b15c" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>nvidia::inferenceserver::client::InferContext::Stat::Stat</definition>
        <argsstring>()</argsstring>
        <name>Stat</name>
        <briefdescription>
<para>Create a new <ref refid="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat" kindref="compound">Stat</ref> object with zero-ed statistics. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="src/clients/c++/request.h" line="544" column="1" bodyfile="src/clients/c++/request.h" bodystart="544" bodyend="548"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
<para>Cumulative statistic of the <ref refid="classnvidia_1_1inferenceserver_1_1client_1_1InferContext" kindref="compound">InferContext</ref>. </para>    </briefdescription>
    <detaileddescription>
<para><simplesect kind="note"><para>For GRPC protocol, &apos;cumulative_send_time_ns&apos; represents the time for marshaling infer request. &apos;cumulative_receive_time_ns&apos; represents the time for unmarshaling infer response. </para></simplesect>
</para>    </detaileddescription>
    <location file="src/clients/c++/request.h" line="528" column="1" bodyfile="src/clients/c++/request.h" bodystart="528" bodyend="549"/>
    <listofallmembers>
      <member refid="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1ad76e90f2ef845eb146acab963bbffd1a" prot="public" virt="non-virtual"><scope>nvidia::inferenceserver::client::InferContext::Stat</scope><name>completed_request_count</name></member>
      <member refid="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1ae113efbf699abdd52d45996dcc7d4689" prot="public" virt="non-virtual"><scope>nvidia::inferenceserver::client::InferContext::Stat</scope><name>cumulative_receive_time_ns</name></member>
      <member refid="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1a5b8451d591204705cfb9d8854f132b18" prot="public" virt="non-virtual"><scope>nvidia::inferenceserver::client::InferContext::Stat</scope><name>cumulative_send_time_ns</name></member>
      <member refid="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1abf5e228bd9de072b92cdbfd06b10c8cf" prot="public" virt="non-virtual"><scope>nvidia::inferenceserver::client::InferContext::Stat</scope><name>cumulative_total_request_time_ns</name></member>
      <member refid="structnvidia_1_1inferenceserver_1_1client_1_1InferContext_1_1Stat_1aa1c18a68160ee9ccb7002fdb40e7b15c" prot="public" virt="non-virtual"><scope>nvidia::inferenceserver::client::InferContext::Stat</scope><name>Stat</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>
